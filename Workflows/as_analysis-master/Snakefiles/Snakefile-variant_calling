import glob
import warnings
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("5.1.4")


# check existence of SAMP variable. it may have already been defined if this
# Snakefile is being included from somewhere else
if 'SAMP1' not in globals():
    def read_samples():
        """Function to get names and dna fastq paths from a sample file
        specified in the configuration. Input file is expected to have 3
        columns: <unique_sample_id> <fastq1_path> <fastq2_path>. Modify
        this function as needed to provide a dictionary of sample_id keys and
        (fastq1, fastq1) values"""
        f = open(config['sample_file'], "r")
        samp_dict = {}
        for line in f:
            words = line.strip().split("\t")
            samp_dict[words[0]] = (words[1], words[2])
        return samp_dict
    SAMP1 = read_samples()

# the user can define config['SAMP_NAMES'] to contain whichever sample names
# they'd like to run the pipeline on
if 'SAMP_NAMES' not in config:
    config['SAMP_NAMES'] = list(SAMP1.keys())
else:
    # double check that the user isn't asking for samples they haven't provided
    user_samps_len = len(config['SAMP_NAMES'])
    config['SAMP_NAMES'] = list(set(SAMP1.keys()).intersection(config['SAMP_NAMES']))
    if len(config['SAMP_NAMES']) != user_samps_len:
        warnings.warn("Not all of the samples requested have provided input. Proceeding with as many samples as is possible...")


if not hasattr(rules, 'all'):
    rule all:
        # if you'd like to run the pipeline on only a subset of the samples,
        # you should specify them in the config['SAMP_NAMES'] variable above
        input:
            config['output_dir'] + "/genotypes/ALL.vcf.gz"

rule align_dna:
    """Align DNA reads using BWA-MEM. Note that we use -R to specify read group
    info for haplotype caller."""
    input:
        ref = config['ref_genome_bwa'],
        fastq1 = lambda wildcards: SAMP1[wildcards.sample][0],
        fastq2 = lambda wildcards: SAMP1[wildcards.sample][1]
    output:
        temp(config['output_dir'] + "/dna_align/{sample}/aligned_dna.sam")
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/align_dna/{sample}.tsv"
    shell:
        "bwa mem -M "
        "-R '@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tPL:ILLUMINA' "
        "-t 1 {input.ref} "
        "{input.fastq1} {input.fastq2} > {output}"

rule sam_to_bam:
    """Convert a SAM file to its more compressed counterpart. Note we use -u to
    create an uncompressed bam file. We use -q to filter alignments with MAPQ
    scores less than 20."""
    input:
        rules.align_dna.output
    output:
        temp(config['output_dir'] + "/dna_align/{sample}/aligned_dna.raw.bam")
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/sam_to_bam/{sample}.tsv"
    shell:
        "samtools view -u -b -F 4 -q 20 {input} >{output}"

rule sort_bam_by_name:
    """Sort the bam output by name (not by coordinates yet)"""
    input:
        rules.sam_to_bam.output
    output:
        config['output_dir'] + "/dna_align/{sample}/aligned_dna.nameSort.bam"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/sort_bam_by_name/{sample}.tsv"
    shell:
        "samtools sort -n {input} >{output}"

rule add_mate_info:
    """Use fixmate to fill in mate coordinates and mate related flags, since
    our data is pair-ended. We need the MC tags (included because we used the
    -m flag) that it creates for markdup"""
    input:
        rules.sort_bam_by_name.output
    output:
        temp(config['output_dir'] + "/dna_align/{sample}/aligned_dna.nameSort.mate.bam")
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/add_mate_info/{sample}.tsv"
    shell:
        "samtools fixmate -m {input} {output}"

rule sort_bam_by_coord:
    """Sort the bam output by coordinates. Needed for markdup use later on."""
    input:
        rules.add_mate_info.output
    output:
        temp(config['output_dir'] + "/dna_align/{sample}/aligned_dna.nameSort.mate.coordSort.bam")
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/sort_bam_by_coord/{sample}.tsv"
    shell:
        "samtools sort -o {output} {input}"

rule rm_dups:
    """Remove duplicates that may have occurred from PCR and index the
    resulting file."""
    input:
        rules.sort_bam_by_coord.output
    output:
        final_bam = config['output_dir'] + "/dna_align/{sample}/aligned_dna.final.bam",
        final_bam_index = config['output_dir'] + "/dna_align/{sample}/aligned_dna.final.bam.bai"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/rm_dups/{sample}.tsv"
    shell:
        "samtools markdup {input} {output.final_bam} && "
        "samtools index -b {output.final_bam}"

rule base_recal:
    """Recalibrate the base quality scores. They might be biased"""
    input:
        ref = config['ref_genome'],
        bam = rules.rm_dups.output.final_bam,
        known_sites = config['dbSNP']
    output:
        config['output_dir'] + "/base_recal/{sample}.recal_data.table"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/base_recal/{sample}.tsv"
    shell:
        "gatk BaseRecalibrator -R {input.ref} -I {input.bam} -known-sites {input.known_sites} -O {output}"

rule apply_base_recal:
    """Apply base quality score recalibration"""
    input:
        ref = config['ref_genome'],
        bam = rules.rm_dups.output.final_bam,
        recal_table = rules.base_recal.output
    output:
        bam = config['output_dir'] + "/base_recal/{sample}.recal.final.bam",
        index = config['output_dir'] + "/base_recal/{sample}.recal.final.bai"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/apply_base_recal/{sample}.tsv"
    shell:
        "gatk ApplyBQSR -R {input.ref} -I {input.bam} --bqsr-recal-file {input.recal_table} -O {output.bam}"

rule haplotype:
    """Make a file with annotated variants"""
    input:
        ref = config['ref_genome'],
        bam = rules.apply_base_recal.output.bam if config['score_recal'] else rules.apply_base_recal.input.bam
    output:
        vcf = config['output_dir'] + "/haplotype/{sample}.snps.g.vcf.gz",
        index = config['output_dir'] + "/haplotype/{sample}.snps.g.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/haplotype/{sample}.tsv"
    shell:
        "gatk HaplotypeCaller "
        "-R {input.ref} -I {input.bam} -O {output.vcf} -ERC GVCF "
        "-G StandardAnnotation -G AS_StandardAnnotation -G StandardHCAnnotation"

rule combine:
    """Combine the g.vcf files"""
    input:
        ref = config['ref_genome'],
        vcf = expand(rules.haplotype.output.vcf, sample=config['SAMP_NAMES'])
    params:
        # create a string with paths to each sample file preceded by '-V '
        # ex: "-V samp1_path -V samp2_path -V samp3_path"
        vcfs = lambda wildcards: " ".join(['-V '+file for file in expand(rules.haplotype.output.vcf, sample=config['SAMP_NAMES'])]),
    output:
        vcf = config['output_dir'] + "/haplotype/ALL.g.vcf.gz",
        index = config['output_dir'] + "/haplotype/ALL.g.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/combine/all.tsv"
    shell:
        "gatk CombineGVCFs -R {input.ref} -O {output.vcf} "
        "-G StandardAnnotation -G AS_StandardAnnotation {params.vcfs}"

rule genotype:
    """Perform joint genotyping on all of the samples"""
    input:
        ref = config['ref_genome'],
        vcf = rules.combine.output.vcf
    output:
        vcf = config['output_dir'] + "/haplotype/ALL.genotype.vcf.gz",
        index = config['output_dir'] + "/haplotype/ALL.genotype.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/genotype/all.tsv"
    shell:
        "gatk GenotypeGVCFs -R {input.ref} -V {input.vcf} -O {output.vcf} "
        "-G StandardAnnotation -G AS_StandardAnnotation "

rule variant_filter:
    """Filter variants by QD, FS, MQ, MQRankSum, ReadPosRankSum, and SOR"""
    input:
        ref = config['ref_genome'],
        vcf = rules.genotype.output.vcf,
        hapmap = config['hapmap'],
        omni = config['omni'],
        project1000G = config['1000G'],
        dbsnp = config['dbSNP']
    output:
        recal = config['output_dir'] + "/variant_filter/ALL.recal",
        recal_idx = config['output_dir'] + "/variant_filter/ALL.recal.idx",
        tranches = config['output_dir'] + "/variant_filter/ALL.tranches"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/variant_filter/all.tsv"
    shell:
        "gatk VariantRecalibrator -R {input.ref} -V {input.vcf} "
        "--resource hapmap,known=false,training=true,truth=true,prior=15.0:{input.hapmap} "
        "--resource omni,known=false,training=true,truth=false,prior=12.0:{input.omni} "
        "--resource 1000G,known=false,training=true,truth=false,prior=10.0:{input.project1000G} "
        "--resource dbsnp,known=true,training=false,truth=false,prior=2.0:{input.dbsnp} "
        "-an QD -an FS -an MQ -an MQRankSum -an ReadPosRankSum -an SOR "
        "-mode SNP -O {output.recal} --tranches-file {output.tranches}"

rule apply_variant_filter:
    """Create a file with only variants that have passed filtration"""
    input:
        ref = config['ref_genome'],
        vcf = rules.genotype.output.vcf,
        recal = rules.variant_filter.output.recal,
        tranches = rules.variant_filter.output.tranches
    output:
        vcf = config['output_dir'] + "/variant_filter/ALL.filter.vcf.gz",
        index = config['output_dir'] + "/variant_filter/ALL.filter.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/apply_variant_filter/all.tsv"
    shell:
        "gatk ApplyVQSR -R {input.ref} -V {input.vcf} -mode SNP "
        "--ts-filter-level {config[target_sensitivity]} "
        "--recal-file {input.recal} --tranches-file {input.tranches} "
        "-O {output.vcf}"

rule variant_hard_filter:
    """Create a file with only variants that pass a hard filter.
    This is an alternative to rules.variant_filter"""
    input:
        ref = config['ref_genome'],
        vcf = rules.genotype.output.vcf,
    params:
        filter_expr = config['filter_expr'],
        filter_name = "snakemake_hard_filter"
    output:
        vcf = config['output_dir'] + "/variant_filter/ALL.hard_filter.vcf.gz",
        index = config['output_dir'] + "/variant_filter/ALL.hard_filter.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/variant_hard_filter/all.tsv"
    shell:
        "gatk VariantFiltration -R {input.ref} -V {input.vcf} -O {output.vcf} "
        "-filter \"{params.filter_expr}\" "
        "--filter-name \"{params.filter_name}\""

rule filter_snps:
    """Extract only SNPs from the filtered VCF file and index the result"""
    input:
        ref = config['ref_genome'],
        vcf = rules.apply_variant_filter.output.vcf if config['score_recal'] else rules.variant_hard_filter.output.vcf
    output:
        vcf = config['output_dir'] + "/variant_filter/ALL.filter.snps.vcf.gz",
        index = config['output_dir'] + "/variant_filter/ALL.filter.snps.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/filter_snps/all.tsv"
    shell:
        "gatk SelectVariants -R {input.ref} -V {input.vcf} -O {output.vcf} "
        "--select-type-to-include SNP"

rule filter_hets:
    """Extract heterozygotes from the filtered VCF file and index the result"""
    input:
        vcf = rules.filter_snps.output.vcf
    output:
        vcf = config['output_dir'] + "/genotypes/ALL.vcf.gz",
        index = config['output_dir'] + "/genotypes/ALL.vcf.gz.tbi"
    conda: "../envs/default.yaml"
    benchmark: config['output_dir'] + "/benchmark/variant_calling/filter_hets/all.tsv"
    shell:
        "zcat {input} | "
        "SnpSift filter \"(countHet() > 0) && (FILTER == 'PASS')\" | "
        "bgzip -c >{output.vcf} && "
        "tabix -p vcf {output.vcf}"
